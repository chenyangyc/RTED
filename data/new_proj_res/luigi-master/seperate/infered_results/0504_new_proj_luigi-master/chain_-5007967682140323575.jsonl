{"function_name": "_generate_task_labels", "function_content": "def _generate_task_labels(self, task):\n    return {label: (task.family if label == 'family' else task.params.get(\n        label)) for label in self.labels}\n", "function_parameter": "(self, task)", "called_function_name": "", "called_function_parameter": "", "called_arguments": "", "user_prompt": "The function `_generate_task_labels` needs to be analyzed is as below:\n```python\ndef _generate_task_labels(self, task):\n    return {label: (task.family if label == 'family' else task.params.get(\n        label)) for label in self.labels}\n\n```\n\nPlease infer the type, fields, methods, and built-in characteristics of each parameter based on its usage within the function `_generate_task_labels`, and using any constraints from the callee if available. Provide the result in JSON format. Please only output the JSON result without any additional explanations or comments.", "llm_output": "```json\n{\n  \"self\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"labels\": {\n        \"type\": \"iterable\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": [\"__iter__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  },\n  \"task\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"family\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"params\": {\n        \"type\": \"dict\",\n        \"fields\": {},\n        \"methods\": [\"get\"],\n        \"built-in\": [\"__getitem__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  }\n}\n```"}
{"function_name": "handle_task_started", "function_content": "def handle_task_started(self, task):\n    self.task_started_counter.labels(**self._generate_task_labels(task)).inc()\n    self.task_execution_time.labels(**self._generate_task_labels(task))\n", "function_parameter": "(self, task)", "called_function_name": "_generate_task_labels", "called_function_parameter": "(self, task)", "called_arguments": "(task)", "user_prompt": "The function `handle_task_started` needs to be analyzed is as below:\n```python\ndef handle_task_started(self, task):\n    self.task_started_counter.labels(**self._generate_task_labels(task)).inc()\n    self.task_execution_time.labels(**self._generate_task_labels(task))\n\n```\nYou are provided with type information for the arguments of the called function. Use this as backward-flow type information to guide your inference in the caller.\nFunction being called: `_generate_task_labels`.\n\nArguments defined in this called function: `(self, task)`.\nArguments passed to this called function: `(task)`.\nThe function belongs to class `PrometheusMetricsCollector`.\nThe constructor of the class is:\n```python\ndef __init__(self, *args, **kwargs):\n    super(PrometheusMetricsCollector, self).__init__()\n    self.registry = CollectorRegistry()\n    config = prometheus(**kwargs)\n    self.labels = list(config.task_parameters_to_use_in_labels)\n    if config.use_task_family_in_labels:\n        self.labels += ['family']\n    if not self.labels:\n        raise ValueError(\n            'Prometheus labels cannot be empty (see prometheus configuration)')\n    self.task_started_counter = Counter('luigi_task_started_total',\n        'number of started luigi tasks', self.labels, registry=self.registry)\n    self.task_failed_counter = Counter('luigi_task_failed_total',\n        'number of failed luigi tasks', self.labels, registry=self.registry)\n    self.task_disabled_counter = Counter('luigi_task_disabled_total',\n        'number of disabled luigi tasks', self.labels, registry=self.registry)\n    self.task_done_counter = Counter('luigi_task_done_total',\n        'number of done luigi tasks', self.labels, registry=self.registry)\n    self.task_execution_time = Gauge('luigi_task_execution_time_seconds',\n        'luigi task execution time in seconds', self.labels, registry=self.\n        registry)\n\n```\n\n\nKnown type information for this called function's parameters:\n```json\n{\n  \"self\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"labels\": {\n        \"type\": \"iterable\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": [\"__iter__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  },\n  \"task\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"family\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"params\": {\n        \"type\": \"dict\",\n        \"fields\": {},\n        \"methods\": [\"get\"],\n        \"built-in\": [\"__getitem__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  }\n}\n```\nPlease infer the type, fields, methods, and built-in characteristics of each parameter based on its usage within the function `handle_task_started`, and using any constraints from the callee if available. Provide the result in JSON format. Please only output the JSON result without any additional explanations or comments.", "llm_output": "```json\n{\n  \"self\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"task_started_counter\": {\n        \"type\": \"class\",\n        \"fields\": {},\n        \"methods\": [\"labels\", \"inc\"],\n        \"built-in\": []\n      },\n      \"task_execution_time\": {\n        \"type\": \"class\",\n        \"fields\": {},\n        \"methods\": [\"labels\"],\n        \"built-in\": []\n      },\n      \"_generate_task_labels\": {\n        \"type\": \"method\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"labels\": {\n        \"type\": \"iterable\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": [\"__iter__\"]\n      }\n    },\n    \"methods\": [\"_generate_task_labels\"],\n    \"built-in\": []\n  },\n  \"task\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"family\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"params\": {\n        \"type\": \"dict\",\n        \"fields\": {},\n        \"methods\": [\"get\"],\n        \"built-in\": [\"__getitem__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  }\n}\n```"}
{"function_name": "update_metrics_task_started", "function_content": "@rpc_method()\ndef update_metrics_task_started(self, task):\n    self._state._metrics_collector.handle_task_started(task)\n", "function_parameter": "(self, task)", "called_function_name": "handle_task_started", "called_function_parameter": "(self, task)", "called_arguments": "(task)", "user_prompt": "The function `update_metrics_task_started` needs to be analyzed is as below:\n```python\n@rpc_method()\ndef update_metrics_task_started(self, task):\n    self._state._metrics_collector.handle_task_started(task)\n\n```\nYou are provided with type information for the arguments of the called function. Use this as backward-flow type information to guide your inference in the caller.\nFunction being called: `handle_task_started`.\n\nArguments defined in this called function: `(self, task)`.\nArguments passed to this called function: `(task)`.\nThe function belongs to class `Scheduler`.\nThe constructor of the class is:\n```python\ndef __init__(self, config=None, resources=None, task_history_impl=None, **\n    kwargs):\n    \"\"\"\n        Keyword Arguments:\n        :param config: an object of class \"scheduler\" or None (in which the global instance will be used)\n        :param resources: a dict of str->int constraints\n        :param task_history_impl: ignore config and use this object as the task history\n        \"\"\"\n    self._config = config or scheduler(**kwargs)\n    self._state = SimpleTaskState(self._config.state_path)\n    if task_history_impl:\n        self._task_history = task_history_impl\n    elif self._config.record_task_history:\n        from luigi import db_task_history\n        self._task_history = db_task_history.DbTaskHistory()\n    else:\n        self._task_history = history.NopHistory()\n    self._resources = resources or configuration.get_config().getintdict(\n        'resources')\n    self._make_task = functools.partial(Task, retry_policy=self._config.\n        _get_retry_policy())\n    self._worker_requests = {}\n    self._paused = False\n    if self._config.batch_emails:\n        self._email_batcher = BatchNotifier()\n    self._state._metrics_collector = MetricsCollectors.get(self._config.\n        metrics_collector, self._config.metrics_custom_import)\n\n```\n\n\nKnown type information for this called function's parameters:\n```json\n{\n  \"self\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"task_started_counter\": {\n        \"type\": \"class\",\n        \"fields\": {},\n        \"methods\": [\"labels\", \"inc\"],\n        \"built-in\": []\n      },\n      \"task_execution_time\": {\n        \"type\": \"class\",\n        \"fields\": {},\n        \"methods\": [\"labels\"],\n        \"built-in\": []\n      },\n      \"_generate_task_labels\": {\n        \"type\": \"method\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"labels\": {\n        \"type\": \"iterable\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": [\"__iter__\"]\n      }\n    },\n    \"methods\": [\"_generate_task_labels\"],\n    \"built-in\": []\n  },\n  \"task\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"family\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"params\": {\n        \"type\": \"dict\",\n        \"fields\": {},\n        \"methods\": [\"get\"],\n        \"built-in\": [\"__getitem__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  }\n}\n```\nPlease infer the type, fields, methods, and built-in characteristics of each parameter based on its usage within the function `update_metrics_task_started`, and using any constraints from the callee if available. Provide the result in JSON format. Please only output the JSON result without any additional explanations or comments.", "llm_output": "```json\n{\n  \"self\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"_state\": {\n        \"type\": \"class\",\n        \"fields\": {\n          \"_metrics_collector\": {\n            \"type\": \"class\",\n            \"fields\": {},\n            \"methods\": [\"handle_task_started\"],\n            \"built-in\": []\n          }\n        },\n        \"methods\": [],\n        \"built-in\": []\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  },\n  \"task\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"family\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"params\": {\n        \"type\": \"dict\",\n        \"fields\": {},\n        \"methods\": [\"get\"],\n        \"built-in\": [\"__getitem__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  }\n}\n```"}
{"function_name": "get_work", "function_content": "@rpc_method(allow_null=False)\ndef get_work(self, host=None, assistant=False, current_tasks=None, worker=\n    None, **kwargs):\n    if self._config.prune_on_get_work:\n        self.prune()\n    assert worker is not None\n    worker_id = worker\n    worker = self._update_worker(worker_id, worker_reference={'host': host},\n        get_work=True)\n    if not worker.enabled:\n        reply = {'n_pending_tasks': 0, 'running_tasks': [], 'task_id': None,\n            'n_unique_pending': 0, 'worker_state': worker.state}\n        return reply\n    if assistant:\n        self.add_worker(worker_id, [('assistant', assistant)])\n    batched_params, unbatched_params, batched_tasks, max_batch_size = (None,\n        None, [], 1)\n    best_task = None\n    if current_tasks is not None:\n        ct_set = set(current_tasks)\n        for task in sorted(self._state.get_active_tasks_by_status(RUNNING),\n            key=self._rank):\n            if task.worker_running == worker_id and task.id not in ct_set:\n                best_task = task\n    if current_tasks is not None:\n        self._reset_orphaned_batch_running_tasks(worker_id)\n    greedy_resources = collections.defaultdict(int)\n    worker = self._state.get_worker(worker_id)\n    if self._paused:\n        relevant_tasks = []\n    elif worker.is_trivial_worker(self._state):\n        relevant_tasks = worker.get_tasks(self._state, PENDING, RUNNING)\n        used_resources = collections.defaultdict(int)\n        greedy_workers = dict()\n    else:\n        relevant_tasks = self._state.get_active_tasks_by_status(PENDING,\n            RUNNING)\n        used_resources = self._used_resources()\n        activity_limit = time.time() - self._config.worker_disconnect_delay\n        active_workers = self._state.get_active_workers(last_get_work_gt=\n            activity_limit)\n        greedy_workers = dict((worker.id, worker.info.get('workers', 1)) for\n            worker in active_workers)\n    tasks = list(relevant_tasks)\n    tasks.sort(key=self._rank, reverse=True)\n    for task in tasks:\n        if (best_task and batched_params and task.family == best_task.\n            family and len(batched_tasks) < max_batch_size and task.\n            is_batchable() and all(task.params.get(name) == value for name,\n            value in unbatched_params.items()) and task.resources ==\n            best_task.resources and self._schedulable(task)):\n            for name, params in batched_params.items():\n                params.append(task.params.get(name))\n            batched_tasks.append(task)\n        if best_task:\n            continue\n        if task.status == RUNNING and task.worker_running in greedy_workers:\n            greedy_workers[task.worker_running] -= 1\n            for resource, amount in (getattr(task, 'resources_running',\n                task.resources) or {}).items():\n                greedy_resources[resource] += amount\n        if self._schedulable(task) and self._has_resources(task.resources,\n            greedy_resources):\n            in_workers = (assistant and task.runnable or worker_id in task.\n                workers)\n            if in_workers and self._has_resources(task.resources,\n                used_resources):\n                best_task = task\n                batch_param_names, max_batch_size = self._state.get_batcher(\n                    worker_id, task.family)\n                if batch_param_names and task.is_batchable():\n                    try:\n                        batched_params = {name: [task.params[name]] for\n                            name in batch_param_names}\n                        unbatched_params = {name: value for name, value in\n                            task.params.items() if name not in batched_params}\n                        batched_tasks.append(task)\n                    except KeyError:\n                        batched_params, unbatched_params = None, None\n            else:\n                workers = itertools.chain(task.workers, [worker_id]\n                    ) if assistant else task.workers\n                for task_worker in workers:\n                    if greedy_workers.get(task_worker, 0) > 0:\n                        greedy_workers[task_worker] -= 1\n                        for resource, amount in (task.resources or {}).items():\n                            greedy_resources[resource] += amount\n                        break\n    reply = self.count_pending(worker_id)\n    if len(batched_tasks) > 1:\n        batch_string = '|'.join(task.id for task in batched_tasks)\n        batch_id = hashlib.new('md5', batch_string.encode('utf-8'),\n            usedforsecurity=False).hexdigest()\n        for task in batched_tasks:\n            self._state.set_batch_running(task, batch_id, worker_id)\n        combined_params = best_task.params.copy()\n        combined_params.update(batched_params)\n        reply['task_id'] = None\n        reply['task_family'] = best_task.family\n        reply['task_module'] = getattr(best_task, 'module', None)\n        reply['task_params'] = combined_params\n        reply['batch_id'] = batch_id\n        reply['batch_task_ids'] = [task.id for task in batched_tasks]\n    elif best_task:\n        self.update_metrics_task_started(best_task)\n        self._state.set_status(best_task, RUNNING, self._config)\n        best_task.worker_running = worker_id\n        best_task.resources_running = best_task.resources.copy()\n        best_task.time_running = time.time()\n        self._update_task_history(best_task, RUNNING, host=host)\n        reply['task_id'] = best_task.id\n        reply['task_family'] = best_task.family\n        reply['task_module'] = getattr(best_task, 'module', None)\n        reply['task_params'] = best_task.params\n    else:\n        reply['task_id'] = None\n    return reply\n", "function_parameter": "(self, host=None, assistant=False, current_tasks=None, worker=\n    None, **kwargs)", "called_function_name": "update_metrics_task_started", "called_function_parameter": "(self, task)", "called_arguments": "(best_task)", "user_prompt": "The function `get_work` needs to be analyzed is as below:\n```python\n@rpc_method(allow_null=False)\ndef get_work(self, host=None, assistant=False, current_tasks=None, worker=\n    None, **kwargs):\n    if self._config.prune_on_get_work:\n        self.prune()\n    assert worker is not None\n    worker_id = worker\n    worker = self._update_worker(worker_id, worker_reference={'host': host},\n        get_work=True)\n    if not worker.enabled:\n        reply = {'n_pending_tasks': 0, 'running_tasks': [], 'task_id': None,\n            'n_unique_pending': 0, 'worker_state': worker.state}\n        return reply\n    if assistant:\n        self.add_worker(worker_id, [('assistant', assistant)])\n    batched_params, unbatched_params, batched_tasks, max_batch_size = (None,\n        None, [], 1)\n    best_task = None\n    if current_tasks is not None:\n        ct_set = set(current_tasks)\n        for task in sorted(self._state.get_active_tasks_by_status(RUNNING),\n            key=self._rank):\n            if task.worker_running == worker_id and task.id not in ct_set:\n                best_task = task\n    if current_tasks is not None:\n        self._reset_orphaned_batch_running_tasks(worker_id)\n    greedy_resources = collections.defaultdict(int)\n    worker = self._state.get_worker(worker_id)\n    if self._paused:\n        relevant_tasks = []\n    elif worker.is_trivial_worker(self._state):\n        relevant_tasks = worker.get_tasks(self._state, PENDING, RUNNING)\n        used_resources = collections.defaultdict(int)\n        greedy_workers = dict()\n    else:\n        relevant_tasks = self._state.get_active_tasks_by_status(PENDING,\n            RUNNING)\n        used_resources = self._used_resources()\n        activity_limit = time.time() - self._config.worker_disconnect_delay\n        active_workers = self._state.get_active_workers(last_get_work_gt=\n            activity_limit)\n        greedy_workers = dict((worker.id, worker.info.get('workers', 1)) for\n            worker in active_workers)\n    tasks = list(relevant_tasks)\n    tasks.sort(key=self._rank, reverse=True)\n    for task in tasks:\n        if (best_task and batched_params and task.family == best_task.\n            family and len(batched_tasks) < max_batch_size and task.\n            is_batchable() and all(task.params.get(name) == value for name,\n            value in unbatched_params.items()) and task.resources ==\n            best_task.resources and self._schedulable(task)):\n            for name, params in batched_params.items():\n                params.append(task.params.get(name))\n            batched_tasks.append(task)\n        if best_task:\n            continue\n        if task.status == RUNNING and task.worker_running in greedy_workers:\n            greedy_workers[task.worker_running] -= 1\n            for resource, amount in (getattr(task, 'resources_running',\n                task.resources) or {}).items():\n                greedy_resources[resource] += amount\n        if self._schedulable(task) and self._has_resources(task.resources,\n            greedy_resources):\n            in_workers = (assistant and task.runnable or worker_id in task.\n                workers)\n            if in_workers and self._has_resources(task.resources,\n                used_resources):\n                best_task = task\n                batch_param_names, max_batch_size = self._state.get_batcher(\n                    worker_id, task.family)\n                if batch_param_names and task.is_batchable():\n                    try:\n                        batched_params = {name: [task.params[name]] for\n                            name in batch_param_names}\n                        unbatched_params = {name: value for name, value in\n                            task.params.items() if name not in batched_params}\n                        batched_tasks.append(task)\n                    except KeyError:\n                        batched_params, unbatched_params = None, None\n            else:\n                workers = itertools.chain(task.workers, [worker_id]\n                    ) if assistant else task.workers\n                for task_worker in workers:\n                    if greedy_workers.get(task_worker, 0) > 0:\n                        greedy_workers[task_worker] -= 1\n                        for resource, amount in (task.resources or {}).items():\n                            greedy_resources[resource] += amount\n                        break\n    reply = self.count_pending(worker_id)\n    if len(batched_tasks) > 1:\n        batch_string = '|'.join(task.id for task in batched_tasks)\n        batch_id = hashlib.new('md5', batch_string.encode('utf-8'),\n            usedforsecurity=False).hexdigest()\n        for task in batched_tasks:\n            self._state.set_batch_running(task, batch_id, worker_id)\n        combined_params = best_task.params.copy()\n        combined_params.update(batched_params)\n        reply['task_id'] = None\n        reply['task_family'] = best_task.family\n        reply['task_module'] = getattr(best_task, 'module', None)\n        reply['task_params'] = combined_params\n        reply['batch_id'] = batch_id\n        reply['batch_task_ids'] = [task.id for task in batched_tasks]\n    elif best_task:\n        self.update_metrics_task_started(best_task)\n        self._state.set_status(best_task, RUNNING, self._config)\n        best_task.worker_running = worker_id\n        best_task.resources_running = best_task.resources.copy()\n        best_task.time_running = time.time()\n        self._update_task_history(best_task, RUNNING, host=host)\n        reply['task_id'] = best_task.id\n        reply['task_family'] = best_task.family\n        reply['task_module'] = getattr(best_task, 'module', None)\n        reply['task_params'] = best_task.params\n    else:\n        reply['task_id'] = None\n    return reply\n\n```\nYou are provided with type information for the arguments of the called function. Use this as backward-flow type information to guide your inference in the caller.\nFunction being called: `update_metrics_task_started`.\n\nArguments defined in this called function: `(self, task)`.\nArguments passed to this called function: `(best_task)`.\nThe function belongs to class `Scheduler`.\nThe constructor of the class is:\n```python\ndef __init__(self, config=None, resources=None, task_history_impl=None, **\n    kwargs):\n    \"\"\"\n        Keyword Arguments:\n        :param config: an object of class \"scheduler\" or None (in which the global instance will be used)\n        :param resources: a dict of str->int constraints\n        :param task_history_impl: ignore config and use this object as the task history\n        \"\"\"\n    self._config = config or scheduler(**kwargs)\n    self._state = SimpleTaskState(self._config.state_path)\n    if task_history_impl:\n        self._task_history = task_history_impl\n    elif self._config.record_task_history:\n        from luigi import db_task_history\n        self._task_history = db_task_history.DbTaskHistory()\n    else:\n        self._task_history = history.NopHistory()\n    self._resources = resources or configuration.get_config().getintdict(\n        'resources')\n    self._make_task = functools.partial(Task, retry_policy=self._config.\n        _get_retry_policy())\n    self._worker_requests = {}\n    self._paused = False\n    if self._config.batch_emails:\n        self._email_batcher = BatchNotifier()\n    self._state._metrics_collector = MetricsCollectors.get(self._config.\n        metrics_collector, self._config.metrics_custom_import)\n\n```\n\n\nKnown type information for this called function's parameters:\n```json\n{\n  \"self\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"_state\": {\n        \"type\": \"class\",\n        \"fields\": {\n          \"_metrics_collector\": {\n            \"type\": \"class\",\n            \"fields\": {},\n            \"methods\": [\"handle_task_started\"],\n            \"built-in\": []\n          }\n        },\n        \"methods\": [],\n        \"built-in\": []\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  },\n  \"task\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"family\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"params\": {\n        \"type\": \"dict\",\n        \"fields\": {},\n        \"methods\": [\"get\"],\n        \"built-in\": [\"__getitem__\"]\n      }\n    },\n    \"methods\": [],\n    \"built-in\": []\n  }\n}\n```\nPlease infer the type, fields, methods, and built-in characteristics of each parameter based on its usage within the function `get_work`, and using any constraints from the callee if available. Provide the result in JSON format. Please only output the JSON result without any additional explanations or comments.", "llm_output": "```json\n{\n  \"self\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"_config\": {\n        \"type\": \"class\",\n        \"fields\": {\n          \"prune_on_get_work\": {\n            \"type\": \"bool\",\n            \"fields\": {},\n            \"methods\": [],\n            \"built-in\": []\n          },\n          \"worker_disconnect_delay\": {\n            \"type\": \"unknown\",\n            \"fields\": {},\n            \"methods\": [],\n            \"built-in\": []\n          }\n        },\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"_state\": {\n        \"type\": \"class\",\n        \"fields\": {\n          \"_metrics_collector\": {\n            \"type\": \"class\",\n            \"fields\": {},\n            \"methods\": [\"handle_task_started\"],\n            \"built-in\": []\n          }\n        },\n        \"methods\": [\"get_active_tasks_by_status\", \"get_worker\", \"get_active_workers\", \"set_batch_running\", \"set_status\", \"get_batcher\"],\n        \"built-in\": []\n      },\n      \"_paused\": {\n        \"type\": \"bool\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      }\n    },\n    \"methods\": [\"prune\", \"_update_worker\", \"add_worker\", \"_reset_orphaned_batch_running_tasks\", \"_used_resources\", \"_rank\", \"_schedulable\", \"_has_resources\", \"count_pending\", \"update_metrics_task_started\", \"_update_task_history\"],\n    \"built-in\": []\n  },\n  \"host\": {\n    \"type\": \"str\",\n    \"fields\": {},\n    \"methods\": [],\n    \"built-in\": []\n  },\n  \"assistant\": {\n    \"type\": \"bool\",\n    \"fields\": {},\n    \"methods\": [],\n    \"built-in\": []\n  },\n  \"current_tasks\": {\n    \"type\": \"list\",\n    \"fields\": {},\n    \"methods\": [],\n    \"built-in\": [\"__iter__\"]\n  },\n  \"worker\": {\n    \"type\": \"class\",\n    \"fields\": {\n      \"enabled\": {\n        \"type\": \"bool\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"state\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      },\n      \"info\": {\n        \"type\": \"dict\",\n        \"fields\": {},\n        \"methods\": [\"get\"],\n        \"built-in\": [\"__getitem__\"]\n      },\n      \"id\": {\n        \"type\": \"unknown\",\n        \"fields\": {},\n        \"methods\": [],\n        \"built-in\": []\n      }\n    },\n    \"methods\": [\"is_trivial_worker\", \"get_tasks\"],\n    \"built-in\": []\n  },\n  \"kwargs\": {\n    \"type\": \"dict\",\n    \"fields\": {},\n    \"methods\": [],\n    \"built-in\": []\n  }\n}\n```"}
